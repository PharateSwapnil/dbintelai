{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new OntotextGraphDBQAChain chain...\u001b[0m\n",
      "Generated SPARQL:\n",
      "\u001b[32;1m\u001b[1;3mPREFIX : <http://proton.semanticweb.org/protonsys#>\n",
      "PREFIX default1: <http://iec.ch/TC57/CIM101#>\n",
      "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
      "\n",
      "SELECT (COUNT(?transformer) AS ?count)\n",
      "WHERE {\n",
      "  ?transformer rdf:type default1:PowerTransformer .\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{\n",
      "  \"query\": \"count of transformers\",\n",
      "  \"result\": \"The count of transformers is 1.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.graphs import OntotextGraphDBGraph\n",
    "from langchain.chains import OntotextGraphDBQAChain\n",
    "from typing import Dict, TypedDict\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyB1j50tKq4yMm4vOQrqWb9yZ1p-G8ZP07Q\"\n",
    "\n",
    "# Initialize LLM\n",
    "# llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "# Connect to Ontotext GraphDB\n",
    "graph = OntotextGraphDBGraph(\n",
    "    query_endpoint=\"http://LP148:7200/repositories/genai_graph_DB\",\n",
    "    query_ontology=\"CONSTRUCT {?s ?p ?o} WHERE {?s ?p ?o}\"\n",
    ")\n",
    "\n",
    "# Define prompt template for query generation\n",
    "template = \"\"\"Convert this question into an optimized GraphDB query with appropriate filters: {query}\"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"query\"], template=template)\n",
    "\n",
    "# Initialize query chain\n",
    "chain = OntotextGraphDBQAChain.from_llm(\n",
    "    llm=llm,\n",
    "    graph=graph,\n",
    "    verbose=True,\n",
    "    allow_dangerous_requests=True,\n",
    "    result_limit=100 \n",
    ")\n",
    "\n",
    "\n",
    "def define_workflow(question):\n",
    "    workflow = StateGraph(GraphState)\n",
    "    workflow.add_node(\"process_query\", lambda x: {\"result\": chain.invoke(question)})\n",
    "    # Define edges\n",
    "    workflow.set_entry_point(\"process_query\")\n",
    "    workflow.set_finish_point(\"process_query\")\n",
    "    \n",
    "    # Compile the graph\n",
    "    app = workflow.compile()\n",
    "    \n",
    "    return app\n",
    "\n",
    "def execute_query(question):\n",
    "    \"\"\"Executes a query on Ontotext GraphDB and handles large result sets.\"\"\"\n",
    "    try:\n",
    "        workflow_app = define_workflow(question)\n",
    "        result = workflow_app.invoke({\"query\": question})\n",
    "        \n",
    "        # Extract the query and the result from the response\n",
    "        query = result.get(\"query\", \"\")\n",
    "        query_result = result.get(\"result\", {}).get(\"result\", \"\")\n",
    "        \n",
    "        if len(query_result) > 4000:\n",
    "            return json.dumps({\n",
    "                \"query\": query,\n",
    "                \"truncated_result\": query_result[:4000] + \"...\",\n",
    "                \"note\": \"Result was truncated due to size. Please refine your query.\"\n",
    "            }, indent=2)\n",
    "        \n",
    "        # Return the query along with the result\n",
    "        return json.dumps({\n",
    "            \"query\": query,\n",
    "            \"result\": query_result\n",
    "        }, indent=2)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error processing request: {str(e)}\"\n",
    "\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    question = \"count of transformers\"\n",
    "    result = execute_query(question)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sweetviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "connection to server at \"0.0.0.0\", port 5000 failed: Cannot assign requested address (0x00002741/10049)\n\tIs the server running on that host and accepting TCP/IP connections?\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 60\u001b[0m\n\u001b[0;32m     57\u001b[0m     report\u001b[38;5;241m.\u001b[39mshow_html(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msweetviz_report.html\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Connect to PostgreSQL\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[43mpsycopg2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0.0.0.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdbname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmydatabase\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmyuser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmypassword\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Get schema info\u001b[39;00m\n\u001b[0;32m     63\u001b[0m schema_info \u001b[38;5;241m=\u001b[39m get_schema_info(conn)\n",
      "File \u001b[1;32mc:\\Users\\SwapnilPharate\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\psycopg2\\__init__.py:122\u001b[0m, in \u001b[0;36mconnect\u001b[1;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     kwasync[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masync_\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masync_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    121\u001b[0m dsn \u001b[38;5;241m=\u001b[39m _ext\u001b[38;5;241m.\u001b[39mmake_dsn(dsn, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 122\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_factory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwasync\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     conn\u001b[38;5;241m.\u001b[39mcursor_factory \u001b[38;5;241m=\u001b[39m cursor_factory\n",
      "\u001b[1;31mOperationalError\u001b[0m: connection to server at \"0.0.0.0\", port 5000 failed: Cannot assign requested address (0x00002741/10049)\n\tIs the server running on that host and accepting TCP/IP connections?\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import sweetviz as sv\n",
    "\n",
    "def get_schema_info(conn):\n",
    "    \"\"\"Fetch schema details for all schemas in the database.\"\"\"\n",
    "    cur = conn.cursor()\n",
    "    query = \"\"\"\n",
    "    SELECT table_schema, table_name, column_name, data_type\n",
    "    FROM information_schema.columns;\n",
    "    \"\"\"\n",
    "    cur.execute(query)\n",
    "    schema_info = cur.fetchall()\n",
    "    organized_schema = {}\n",
    "    \n",
    "    for schema, table, column, dtype in schema_info:\n",
    "        if schema not in organized_schema:\n",
    "            organized_schema[schema] = {}\n",
    "        if table not in organized_schema[schema]:\n",
    "            organized_schema[schema][table] = {}\n",
    "        \n",
    "        organized_schema[schema][table][column] = dtype\n",
    "    \n",
    "    cur.close()\n",
    "    return organized_schema\n",
    "\n",
    "def generate_sql_query(prompt, schema_info):\n",
    "    \"\"\"Ask LLM to generate SQL based on schema and user question.\"\"\"\n",
    "    # Create a structured schema string to pass to the LLM\n",
    "    schema_text = \"\"\n",
    "    \n",
    "    for schema, tables in schema_info.items():\n",
    "        schema_text += f\"Schema: {schema}\\n\"\n",
    "        for table, columns in tables.items():\n",
    "            columns_text = \", \".join([f\"{col}: {dtype}\" for col, dtype in columns.items()])\n",
    "            schema_text += f\"Table: {table}\\nColumns: {{{columns_text}}}\\n\"\n",
    "    \n",
    "    # Construct the prompt for the LLM\n",
    "    full_prompt = f\"Database Schema Information:\\n{schema_text}\\n\\nUser Query: {prompt}\\nGenerate an SQL query:\"\n",
    "    \n",
    "    # Replace with your LLM code (e.g., OpenAI)\n",
    "    response = \"Generated SQL Query: SELECT * FROM customers;\"  # Replace with actual LLM API call\n",
    "    return response  # Here, you would return the LLM's response\n",
    "\n",
    "def execute_query(conn, query):\n",
    "    \"\"\"Run the generated SQL query on PostgreSQL.\"\"\"\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(query)\n",
    "    results = cur.fetchall()\n",
    "    cur.close()\n",
    "    return results\n",
    "\n",
    "def visualize_data(data):\n",
    "    \"\"\"Visualize the data using sweetviz\"\"\"\n",
    "    df = pd.DataFrame(data)\n",
    "    report = sv.analyze(df)\n",
    "    report.show_html('sweetviz_report.html')\n",
    "\n",
    "# Connect to PostgreSQL\n",
    "conn = psycopg2.connect(host=\"0.0.0.0\", port=5000, dbname=\"mydatabase\", user=\"myuser\", password=\"mypassword\")\n",
    "# for this you can take credentials from main.py\n",
    "\n",
    "# Get schema info\n",
    "schema_info = get_schema_info(conn)\n",
    "\n",
    "# Generate SQL using LLM\n",
    "user_prompt = \"Get all customers from the public schema.\"\n",
    "generated_sql = generate_sql_query(user_prompt, schema_info)\n",
    "\n",
    "# Execute SQL\n",
    "query_result = execute_query(conn, generated_sql)\n",
    "\n",
    "# Visualize data\n",
    "visualize_data(query_result)\n",
    "\n",
    "conn.close()\n",
    "    \n",
    "# In this script, we first connect to a PostgreSQL database using the  psycopg2  library. We then define a function  get_schema_info  to fetch schema details for all schemas in the database. Next, we define a function  generate_sql_query  to ask the large language model (LLM) to generate SQL based on the schema and user question. \n",
    "# The  execute_query  function runs the generated SQL query on PostgreSQL. Finally, we define a function  visualize_data  to visualize the data using the  sweetviz  library. \n",
    "# We then connect to the PostgreSQL database, get the schema information, generate SQL using the LLM, execute the SQL query, and visualize the data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
